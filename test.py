import gradio as gr
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
import os
import io

# æ ¸å¿ƒé‚è¼¯ 1: ç‰¹å¾µæå– (Feature Extraction)
def extract_features(audio_path, sr=22050):
    """è¼‰å…¥éŸ³è¨Šä¸¦æå– Chroma (éŸ³é«˜/å’Œè²) å’Œ RMS (èƒ½é‡/éŸ³é‡) ç‰¹å¾µã€‚"""
    try:
        # è¼‰å…¥éŸ³è¨Š
        y, sr = librosa.load(audio_path, sr=sr, mono=True)
    except Exception as e:
        # Gradio åœ¨éŒ„éŸ³æ™‚ï¼Œå¦‚æœä½¿ç”¨è€…æ²’æœ‰éŒ„è£½å…§å®¹å°±æäº¤ï¼Œå¯èƒ½æœƒå‚³å…¥ None æˆ–ç©ºè·¯å¾‘
        if not audio_path:
            raise gr.Error("è«‹éŒ„è£½æˆ–ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆã€‚")
        raise gr.Error(f"è¼‰å…¥éŸ³è¨Šæª”æ¡ˆå¤±æ•—: {e}")

    # --- æ–°å¢ ---
    # æª¢æŸ¥éŸ³è¨Šé•·åº¦ï¼Œé¿å…å› æª”æ¡ˆéçŸ­å°è‡´ librosa åˆ†ææ™‚å‡ºéŒ¯
    MIN_SAMPLES = 2048 # FFT é‹ç®—éœ€è¦ä¸€å®šçš„æ¨£æœ¬æ•¸
    if len(y) < MIN_SAMPLES:
        raise gr.Error(f"éŸ³è¨Šé•·åº¦éçŸ­ ({len(y)/sr:.2f} ç§’)ï¼Œç„¡æ³•é€²è¡Œæœ‰æ•ˆåˆ†æã€‚è«‹æä¾›è‡³å°‘ {MIN_SAMPLES/sr:.2f} ç§’çš„éŸ³è¨Šã€‚")

    # 1. Chroma feature (éŸ³é«˜/å’Œè²å…§å®¹)
    # ä½¿ç”¨ CQT (Constant-Q Transform) å¾—åˆ°æ›´å¥½çš„éŸ³é«˜è§£æåº¦ï¼Œå†è½‰æ›ç‚º Chroma
    # Chroma å‘é‡ (12ç¶­) ä»£è¡¨äº†æ¯å€‹å…«åº¦å…§çš„éŸ³é«˜åˆ†ä½ˆ
    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
    
    # 2. RMS (èƒ½é‡/éŸ³é‡) - ä½œç‚ºç°¡å–®çš„æ­Œè²æ´»å‹•åµæ¸¬ (VAD)
    rms = librosa.feature.rms(y=y)
    
    # åˆä½µç‰¹å¾µï¼š[12ç¶­ Chroma, 1ç¶­ RMS]
    # è½‰ç½®å¾Œæˆç‚º (N_frames, 13) çš„çŸ©é™£
    features = np.vstack([chroma, rms])
    
    # è¿”å›è½‰ç½®å¾Œçš„ç‰¹å¾µçŸ©é™£å’Œå–æ¨£ç‡
    return features.T, sr, y

# æ ¸å¿ƒé‚è¼¯ 2: DTW å°é½Š (DTW Alignment)
def align_dtw(features_input, features_ref):
    """
    åŸ·è¡Œå‹•æ…‹æ™‚é–“è¦æ•´ (DTW) ä»¥å°é½Šå…©æ®µæ­Œè²çš„æ™‚é–“è»¸ã€‚
    DTW å°‹æ‰¾å¾ (0, 0) åˆ° (N, M) æˆæœ¬æœ€ä½çš„è·¯å¾‘ï¼Œä»¥æœ€å°åŒ–æ™‚é–“è¦æ•´å¾Œçš„å·®ç•°ã€‚
    """
    # ä½¿ç”¨æ­å¹¾é‡Œå¾—è·é›¢ä½œç‚ºè·é›¢åº¦é‡ (metric)
    D, wp = librosa.sequence.dtw(
        X=features_input.T,  # X è»¸ (Input)
        Y=features_ref.T,    # Y è»¸ (Reference)
        metric='euclidean'
    )
    # --- ä¿®æ­£ ---
    # librosa.dtw è¿”å›çš„ wp (warping path) æ˜¯ä¸€å€‹ (N_path, 2) çš„é™£åˆ—ï¼Œ
    # å¾ŒçºŒåˆ†æç¨‹å¼ç¢¼ `for k, (i, j) in enumerate(wp):` é æœŸçš„æ˜¯é€™ç¨®å½¢ç‹€ã€‚
    # åŸæœ¬çš„ `wp.T` æœƒå°‡å…¶è½‰ç½®ç‚º (2, N_path)ï¼Œå°è‡´è¿´åœˆè§£åŒ…æ™‚ç™¼ç”Ÿ "too many values to unpack" éŒ¯èª¤ã€‚
    # å› æ­¤ï¼Œæˆ‘å€‘ç›´æ¥è¿”å›åŸå§‹çš„ wpã€‚
    return D, wp

# æ ¸å¿ƒé‚è¼¯ 3: çµæœåˆ†æèˆ‡å»ºè­°ç”Ÿæˆ (Analysis and Feedback Generation)
def analyze_results(wp, D, features_input, features_ref, sr):
    """æ ¹æ“š DTW çµæœåˆ†æé€Ÿåº¦å’ŒéŸ³é«˜å·®ç•°ï¼Œä¸¦ç”Ÿæˆå»ºè­°ã€‚"""
    feedback = []
    
    # è¨ˆç®—æ¯å¹€çš„æ™‚é–“é•·åº¦
    HOP_LENGTH = 512 # Librosa é è¨­çš„ Frame Hop é•·åº¦
    TIME_PER_FRAME = HOP_LENGTH / sr
    
    # --- 1. æ•´é«”ç›¸ä¼¼åº¦åˆ†æ•¸ (Overall Similarity Score) ---
    # ç¸½æˆæœ¬ (Total Cost) 
    total_cost = D[-1, -1]
    # æ­£è¦åŒ–æˆæœ¬ (Normalized Cost) ä½œç‚ºç›¸ä¼¼åº¦æŒ‡æ¨™ (å€¼è¶Šä½è¶Šç›¸ä¼¼)
    normalized_cost = total_cost / len(wp)
    similarity_score = f"{normalized_cost:.4f}"
    
    # --- 2. æ•´é«”ç¯€å¥/é€Ÿåº¦åˆ†æ (Global Tempo Analysis) ---
    input_frames = features_input.shape[0]
    ref_frames = features_ref.shape[0]
    avg_slope = input_frames / ref_frames
    
    tempo_suggestion = "**æ•´é«”ç¯€å¥è©•ä¼° (Global Tempo):** "
    if avg_slope > 1.15: # Input æ¯” Reference é•· 15% ä»¥ä¸Š (å”±å¾—å¤ªæ…¢)
        tempo_suggestion += f"æ‚¨çš„æ­Œè²æ¯”åƒè€ƒéŸ³è¨Šæ…¢äº†ç´„ {avg_slope * 100 - 100:.1f}%ã€‚å»ºè­°æ‚¨æ•´é«”åŠ å¿«æ¼”å”±é€Ÿåº¦ã€‚"
    elif avg_slope < 0.85: # Input æ¯” Reference çŸ­ 15% ä»¥ä¸Š (å”±å¾—å¤ªå¿«)
        tempo_suggestion += f"æ‚¨çš„æ­Œè²æ¯”åƒè€ƒéŸ³è¨Šå¿«äº†ç´„ {100 - avg_slope * 100:.1f}%ã€‚å»ºè­°æ‚¨æ•´é«”æ”¾æ…¢æ¼”å”±é€Ÿåº¦ã€‚"
    else:
        tempo_suggestion += "æ‚¨çš„æ•´é«”ç¯€å¥æŒæ¡å¾—å¾ˆå¥½ï¼Œèˆ‡åƒè€ƒéŸ³è¨Šå¤§è‡´åŒæ­¥ã€‚"
    
    feedback.append(tempo_suggestion)
    
    # --- 3. å±€éƒ¨æ™‚åºèˆ‡éŸ³é«˜å•é¡Œ (Local Timing and Pitch Issues) ---
    feedback.append("\n**å…·é«”å±€éƒ¨æ”¹é€²å»ºè­° (Local Feedback):**")
    
    # è¨ˆç®—æ¯æ¢è·¯å¾‘é»çš„å±€éƒ¨æˆæœ¬ (Local Cost) ä½œç‚ºä¸åŒ¹é…ç¨‹åº¦çš„æŒ‡æ¨™
    local_costs = np.zeros(len(wp))
    for k, (i, j) in enumerate(wp):
        # ä½¿ç”¨ cost matrix D çš„å€¼ï¼Œä¸¦é™¤ä»¥è·¯å¾‘è·é›¢ (i+j) ä¾†é€²è¡Œå±€éƒ¨æ¯”è¼ƒ
        local_costs[k] = D[i, j] / (i + j + 1e-6) # åŠ ä¸Šä¸€å€‹æ¥µå°å€¼é¿å…é™¤ä»¥é›¶

    # æ‰¾å‡ºå±€éƒ¨æˆæœ¬é¡¯è‘—é«˜æ–¼å¹³å‡å€¼ (ä¾‹å¦‚ 1.5 å€‹æ¨™æº–å·®ä»¥ä¸Š) çš„é»
    mean_cost = np.mean(local_costs)
    std_cost = np.std(local_costs)
    threshold = mean_cost + 1.5 * std_cost 
    
    high_cost_points = np.where(local_costs > threshold)[0]
    
    if high_cost_points.size == 0:
        feedback.append("â€¢ æ²’æœ‰æª¢æ¸¬åˆ°æ˜é¡¯çš„å±€éƒ¨æ™‚åºæˆ–éŸ³é«˜å•é¡Œï¼Œè¡¨ç¾å„ªç•°ï¼")
    else:
        # å°‡é€£çºŒçš„é«˜æˆæœ¬é»åˆ†çµ„ç‚ºå–®å€‹å•é¡Œå€æ®µ (Issue Segment)
        issue_groups = []
        if high_cost_points.size > 0:
            current_group = [high_cost_points[0]]
            for i in range(1, len(high_cost_points)):
                if high_cost_points[i] == high_cost_points[i-1] + 1:
                    current_group.append(high_cost_points[i])
                else:
                    issue_groups.append(current_group)
                    current_group = [high_cost_points[i]]
            issue_groups.append(current_group)
        
        # é™åˆ¶æœ€å¤šé¡¯ç¤º 5 å€‹å»ºè­°ï¼Œé¿å…ç‰ˆé¢éé•·
        for group in issue_groups[:5]:
            start_k, end_k = group[0], group[-1]
            
            # å°æ‡‰åˆ° Input å’Œ Reference çš„å¹€ç´¢å¼•
            i_start, j_start = wp[start_k]
            i_end, j_end = wp[end_k]
            
            # å°‡ Input å¹€ç´¢å¼•è½‰æ›ç‚ºæ™‚é–“ (ç§’)
            time_start = i_start * TIME_PER_FRAME
            time_end = i_end * TIME_PER_FRAME
            
            # --- å±€éƒ¨éŸ³é«˜ (Pitch) åˆ†æ ---
            # Chroma ç‰¹å¾µä½æ–¼ features_input/ref çš„å‰ 12 è¡Œ (0-11)
            chroma_input_seg = features_input[i_start:i_end+1, :12]
            chroma_ref_seg = features_ref[j_start:j_end+1, :12]
            
            pitch_suggestion = ""
            if chroma_input_seg.size > 0 and chroma_ref_seg.size > 0:
                # è¨ˆç®—è©²å€æ®µå…§ Input å’Œ Ref çš„ä¸»è¦éŸ³é«˜ (Peak Chroma Bin)
                input_peak_bin = np.mean(np.argmax(chroma_input_seg, axis=1))
                ref_peak_bin = np.mean(np.argmax(chroma_ref_seg, axis=1))
                # pitch_diff æ­£å€¼: åé«˜ (Input Chroma Bin > Ref Chroma Bin)
                pitch_diff = input_peak_bin - ref_peak_bin 
                
                # è¨ˆç®—å±€éƒ¨é€Ÿåº¦ (Local Speed) å·®ç•°
                frames_input_seg = i_end - i_start
                frames_ref_seg = j_end - j_start
                local_slope = frames_input_seg / (frames_ref_seg + 1e-6) # é¿å…é™¤ä»¥é›¶

                if abs(pitch_diff) > 0.8: # éŸ³é«˜å·®ç•°è¶…éç´„ 0.8 å€‹åŠéŸ³
                    pitch_level = "åé«˜" if pitch_diff > 0 else "åä½"
                    pitch_suggestion = f"éŸ³é«˜æ˜é¡¯**{pitch_level}**ï¼Œå¹³å‡åå·®ç´„ {abs(pitch_diff):.1f} å€‹åŠéŸ³ã€‚"
                elif local_slope > 1.8:
                    pitch_suggestion = "**æ™‚åºåš´é‡æ‹–æ²“**ï¼Œæ‚¨çš„æ¼”å”±å¤ªæ…¢äº†ï¼Œéœ€è¦æ›´æœæ–·åœ°é€²å…¥ä¸‹ä¸€å€‹æ¨‚å¥ã€‚"
                elif local_slope < 0.5:
                    pitch_suggestion = "**æ™‚åºåš´é‡è¶…å‰**ï¼Œæ‚¨çš„æ¼”å”±å¤ªå¿«äº†ï¼Œè«‹ä»”ç´°è†è½åƒè€ƒéŸ³è¨Šçš„é–“éš”ã€‚"
                else:
                    pitch_suggestion = "éŸ³æº–æˆ–éŸ³è‰²ä¸åŒ¹é…ã€‚è«‹å°ˆæ³¨æ–¼è©²æ¨‚å¥çš„éŸ³æº–ç©©å®šæ€§ã€‚"

            
                feedback.append(f"â€¢ **æ™‚é–“ {time_start:.2f} ç§’åˆ° {time_end:.2f} ç§’:** {pitch_suggestion}")
        
        if len(issue_groups) > 5:
            feedback.append("â€¢ ... (åƒ…é¡¯ç¤ºå‰ 5 å€‹æœ€é¡¯è‘—çš„å•é¡Œé»)")

    return similarity_score, '\n'.join(feedback)

# æ ¸å¿ƒé‚è¼¯ 4: DTW å¯è¦–åŒ– (DTW Visualization)
def plot_dtw_path(D, wp, sr):
    """ç¹ªè£½ç´¯ç©æˆæœ¬çŸ©é™£å’Œæœ€ä½³è¦æ•´è·¯å¾‘ã€‚"""
    fig = plt.figure(figsize=(10, 8))
    ax = fig.add_subplot(111)
    
    # é¡¯ç¤ºç´¯ç©æˆæœ¬çŸ©é™£ (Accumulated Cost Matrix)
    # D çš„å½¢ç‹€ç‚º (input_frames, ref_frames)ã€‚specshow å°‡ç¬¬ä¸€ç¶­å°æ‡‰ y è»¸ï¼Œç¬¬äºŒç¶­å°æ‡‰ x è»¸ã€‚
    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='time', ax=ax)
    fig.colorbar(img, ax=ax, format='%+2.0f', label='ç´¯ç©æˆæœ¬ (Accumulated Cost)')
    ax.set(title='DTW ç´¯ç©æˆæœ¬çŸ©é™£èˆ‡æœ€ä½³è·¯å¾‘')
    
    # ç¹ªè£½æœ€ä½³è¦æ•´è·¯å¾‘ (Warping Path)
    # wp[:, 0] æ˜¯ input frames, wp[:, 1] æ˜¯ reference frames.
    # æˆ‘å€‘ç¹ªè£½ (ref_time, input_time) ä¾†å°æ‡‰ x, y è»¸ã€‚
    ax.plot(librosa.frames_to_time(wp[:, 1], sr=sr), librosa.frames_to_time(wp[:, 0], sr=sr), 
            marker='o', color='red', linestyle='-', linewidth=2, alpha=0.5, 
            label='æœ€ä½³è¦æ•´è·¯å¾‘ (Warping Path)')
    
    ax.set_xlabel("åƒè€ƒéŸ³è¨Šæ™‚é–“ (Reference Time)")
    ax.set_ylabel("æ‚¨çš„æ­Œè²æ™‚é–“ (Input Time)")
    ax.legend(loc='lower right')
    
    # --- ä¿®æ­£ ---
    # Gradio çš„ gr.Plot å…ƒä»¶å¯ä»¥ç›´æ¥è™•ç† matplotlib çš„ Figure ç‰©ä»¶ï¼Œ
    # é€™æ¯”æ‰‹å‹•è½‰æ›ç‚º bytes æ›´ç°¡æ½”ã€‚
    # æˆ‘å€‘ä¸æ‡‰åœ¨æ­¤è™•å‘¼å« plt.close(fig)ï¼Œå¦å‰‡ Gradio å°‡ç„¡æ³•æ¸²æŸ“å®ƒã€‚
    return fig


# Gradio ä¸»è¦å‡½æ•¸
def singing_evaluator(input_audio_path, ref_audio_path):
    """Gradio æ¥å£çš„ä¸»è¦è™•ç†å‡½æ•¸ã€‚"""
    if not input_audio_path or not ref_audio_path:
        raise gr.Error("è«‹ä¸Šå‚³æˆ–éŒ„è£½æ‚¨çš„æ­Œè²å’Œåƒè€ƒéŸ³è¨Šæª”æ¡ˆã€‚")

    try:
        # 1. ç‰¹å¾µæå–
        features_input, sr, y_input = extract_features(input_audio_path)
        features_ref, sr, y_ref = extract_features(ref_audio_path)
        
        # 2. DTW å°é½Š
        D, wp = align_dtw(features_input, features_ref)
        
        # 3. åˆ†æä¸¦ç”Ÿæˆå»ºè­°
        similarity_score, feedback_text = analyze_results(wp, D, features_input, features_ref, sr)
        
        # 4. å¯è¦–åŒ– DTW è·¯å¾‘
        dtw_plot = plot_dtw_path(D, wp, sr)
        
        # 5. è¿”å›çµæœ
        return similarity_score, feedback_text, dtw_plot, input_audio_path, ref_audio_path
        
    except gr.Error as e:
        # ç›´æ¥æ‹‹å‡º Gradio çš„éŒ¯èª¤ï¼Œä½¿å…¶èƒ½æ¸…æ™°åœ°é¡¯ç¤ºåœ¨ UI ä¸Š
        raise e
    except Exception as e:
        error_message = f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}"
        print(error_message) # åœ¨å¾Œç«¯æ‰“å°è©³ç´°éŒ¯èª¤ä»¥ä¾›èª¿è©¦
        # å‘ç”¨æˆ¶é¡¯ç¤ºä¸€å€‹æ›´å‹å¥½çš„éŒ¯èª¤è¨Šæ¯
        raise gr.Error("åˆ†æå¤±æ•—ï¼Œè«‹æª¢æŸ¥æ‚¨çš„éŸ³è¨Šæª”æ¡ˆæ˜¯å¦æœ‰æ•ˆï¼Œæˆ–ç¨å¾Œå†è©¦ã€‚")

# --- Gradio ç•Œé¢å®šç¾© ---

# æè¿°å’Œæ¨™é¡Œ
title = "ğŸ™ï¸ AI æ­Œè²ç›¸ä¼¼æ€§è©•ä¼°èˆ‡è¼”åŠ©ç³»çµ± (æ”¯æ´éŒ„éŸ³) ğŸ¶"
description = (
    "ä¸Šå‚³æˆ–**å³æ™‚éŒ„è£½**å…©æ®µéŸ³è¨Šæª”æ¡ˆï¼ˆæ‚¨çš„æ­Œè²å’Œåƒè€ƒéŸ³è¨Šï¼‰ï¼Œç³»çµ±å°‡ä½¿ç”¨å‹•æ…‹æ™‚é–“è¦æ•´ (DTW) æŠ€è¡“å°é½ŠéŸ³è»Œï¼Œ"
    "åˆ†æç¯€å¥å’ŒéŸ³é«˜å·®ç•°ï¼Œä¸¦æä¾›å…·é«”çš„æ”¹é€²å»ºè­°ï¼Œä¾‹å¦‚å¹¾ç§’åˆ°å¹¾ç§’å¤ªå¿«æˆ–éŸ³é«˜åä½ã€‚"
)

with gr.Blocks(theme=gr.themes.Soft(), title=title) as demo:
    gr.Markdown(f"# {title}")
    gr.Markdown(description)

    # è¼¸å…¥å€ (å·²åŠ å…¥ microphone ä¾†æº)
    with gr.Row():
        input_audio_upload = gr.Audio(
            type="filepath", 
            label="ğŸ¤ æ‚¨çš„æ­Œè² (Input Audio)", 
            sources=["upload", "microphone"] # æ”¯æ´ä¸Šå‚³å’ŒéŒ„éŸ³
        )
        ref_audio_upload = gr.Audio(
            type="filepath", 
            label="ğŸ§ åƒè€ƒéŸ³è¨Š (Reference Audio)", 
            sources=["upload", "microphone"] # æ”¯æ´ä¸Šå‚³å’ŒéŒ„éŸ³
        )
    
    analyze_btn = gr.Button("ğŸš€ é–‹å§‹åˆ†æèˆ‡è©•ä¼°", variant="primary")
    
    # è¼¸å‡ºå€
    # å°‡ gr.Column è³¦å€¼çµ¦ä¸€å€‹è®Šæ•¸ï¼Œä»¥ä¾¿åœ¨ .success() ä¸­å¼•ç”¨
    result_outputs_group = gr.Column(visible=False) 
    with result_outputs_group:
        gr.Markdown("---")
        gr.Markdown("## ğŸ“‹ è©•ä¼°çµæœ")
        
        with gr.Row():
            score_display = gr.Textbox(label="ç¸½é«”æ­£è¦åŒ–ç›¸ä¼¼åº¦åˆ†æ•¸ (è¶Šä½è¶Šç›¸ä¼¼)", show_label=True, scale=1)
            
        # å°‡ Markdown å…ƒä»¶ä¹Ÿè³¦å€¼çµ¦ä¸€å€‹è®Šæ•¸
        feedback_output = gr.Markdown("### ğŸ“œ å…·é«”æ”¹é€²å»ºè­°")

        dtw_plot_output = gr.Plot(label="DTW è¦æ•´è·¯å¾‘åœ– (Warping Path Visualization)")
        
        gr.Markdown("---")
        gr.Markdown("## ğŸ”Š åŒæ­¥æ’­æ”¾ (è«‹æ‰‹å‹•æŒ‰ä¸‹æ’­æ”¾éµ)")
        
        with gr.Row():
            aligned_input_playback = gr.Audio(label="æ‚¨çš„æ­Œè² (Input)", interactive=False, autoplay=False)
            aligned_ref_playback = gr.Audio(label="åƒè€ƒéŸ³è¨Š (Reference)", interactive=False, autoplay=False)
        gr.Markdown("*æ³¨æ„ï¼šGradio åƒ…æä¾›ä¸¦æ’æ’­æ”¾ï¼Œæ‚¨éœ€è¦æ‰‹å‹•åŒæ™‚é»æ“Šæ’­æ”¾ä»¥é€²è¡Œè½è¦ºä¸Šçš„åŒæ­¥æ¯”å°ã€‚DTW çµæœæ˜¯æ¼”ç®—æ³•ä¸Šå·²å°é½Šçš„ã€‚*")

    # ç¶å®šäº‹ä»¶
    # é»æ“ŠæŒ‰éˆ•å¾Œï¼Œå…ˆå°‡çµæœå€åŸŸè¨­ç‚ºéš±è—ï¼Œä»¥æ¸…é™¤èˆŠçš„çµæœ
    def hide_results():
        return gr.Column(visible=False)

    analyze_btn.click(
        fn=hide_results,
        inputs=None,
        outputs=[result_outputs_group]
    ).then(
        fn=singing_evaluator,
        inputs=[input_audio_upload, ref_audio_upload],
        outputs=[score_display, feedback_output, dtw_plot_output, aligned_input_playback, aligned_ref_playback]
    ).success(
        fn=lambda: gr.Column(visible=True), # æˆåŠŸå¾Œå†é¡¯ç¤ºçµæœ
        inputs=None,
        outputs=result_outputs_group
    )

if __name__ == "__main__":
    demo.launch(share=True)
